{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PW Final Exam\n",
    "# 11/29/2023\n",
    "# By NÃ©dra Mellouli @devinci.fr\n",
    "ChatGPT is forbidden\n",
    "\n",
    "Moodle resources are available"
   ],
   "metadata": {
    "id": "toEt9QL10eAg"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 1 (10 pts)\n",
    "Given data about citrus fruits, let's try to classify the type of a given fruit.\n",
    "The task of this exercise consists of pre-processing the dataset.\n",
    "You have to clean the data citrus.csv  located at moodle\n",
    "\n",
    "\n",
    "1.Load the data from csv with the correct seperator and store it in a dataframe format\n",
    "1. print the data information\n",
    "\n",
    "1.   Define the list of input features (as your explanatory variables) and the target features for a classification task\n",
    "2.   plot  histogramms of the input features and the box plot of your data\n",
    "\n",
    "1.   Plot the correlation matrix\n",
    "1.   define a feature_columns variable composed by the name of all the explanatory varaibels\n",
    "\n",
    "1.  Build a new dataframe called \"data\" containing only the values associated to feature_columns.\n",
    "2. Determine the missing data  and plot the rate of missing values by feature.\n",
    "1. Print the 20 head samples of data having a missing valeus\n",
    "\n",
    "2. Explain your process  to clean the data  \n",
    "\n",
    "2. Code your cleaning process\n",
    "1. Display features distribution for each class.\n",
    "1. Comment the data\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "MmfG56TH0QFG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Exercise 1 (10 pts)\n",
    "\n",
    "# Task 1: Load the data\n",
    "data_path = 'path_to_citrus.csv'  # Replace with the correct path\n",
    "citrus_data = pd.read_csv(data_path, sep=',')  # Adjust the separator if needed\n",
    "\n",
    "# Task 2: Print data information\n",
    "print(citrus_data.info())\n",
    "\n",
    "# Task 3: Define input and target features\n",
    "input_features = ['feature1', 'feature2', 'feature3']  # Replace with actual feature names\n",
    "target_feature = 'target'  # Replace with the name of the target feature\n",
    "\n",
    "# Task 4: Plot histograms and box plots of input features\n",
    "for feature in input_features:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    citrus_data[feature].hist()\n",
    "    plt.title(f'Histogram of {feature}')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    citrus_data.boxplot(column=[feature])\n",
    "    plt.title(f'Box Plot of {feature}')\n",
    "    plt.show()\n",
    "\n",
    "# Task 5: Plot the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(citrus_data[input_features].corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Task 6: Define feature_columns and create a new dataframe\n",
    "feature_columns = input_features.copy()\n",
    "data = citrus_data[feature_columns]\n",
    "\n",
    "# Task 7: Determine and plot missing data rates\n",
    "missing_data = data.isnull().mean()\n",
    "plt.figure(figsize=(10, 4))\n",
    "missing_data.plot(kind='bar')\n",
    "plt.title('Rate of Missing Values by Feature')\n",
    "plt.show()\n",
    "\n",
    "# Task 8: Print 20 head samples with missing values\n",
    "print(data[data.isnull().any(axis=1)].head(20))\n",
    "\n",
    "# Task 9: Explain the data cleaning process (this should be a textual explanation)\n",
    "\n",
    "# Task 10: Code the data cleaning process\n",
    "# Example: data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Task 11: Display features distribution for each class\n",
    "for feature in input_features:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.boxplot(x=target_feature, y=feature, data=citrus_data)\n",
    "    plt.title(f'Feature Distribution for Each Class - {feature}')\n",
    "    plt.show()\n",
    "\n",
    "# Task 12: Comment on the data (this should be a textual commentary)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 2 (10 points)\n",
    "\n",
    "On the cleaned data citrus dataset, we are looking to build a Machine learning model allowing as to distinguish between different fruits.\n",
    "\n",
    "\n",
    "1.   Create a decision tree classifier with a maximum depth of 2 levels using the k-fold cross validation. Hint: take 60% data to train, 20% data to validate. The remaining 20% will be used as testing data to evaluate the prediction accuracy.  \n",
    "2.  Compute the accuracy of the decision tree on the training  step.\n",
    "1.  Compute the accuracy of the decision tree on the testing data\n",
    "2.Plot the tree and select the most impure node at the level 1. Justify your answer\n",
    "1.   Take the samples belonging to the most impure node and apply a k-means to discover more discrimate properties on these samples. You have to give arguments about the fixed value of k.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "Oyjm0hAj0YB7"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Exercise 2 (10 points)\n",
    "\n",
    "# Assuming 'data' is the cleaned citrus dataset\n",
    "# Assuming 'input_features' and 'target_feature' are already defined\n",
    "\n",
    "# Step 1: Split the data into train, validate, and test sets\n",
    "train_data, temp_data = train_test_split(data, test_size=0.4, random_state=42)\n",
    "validate_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# Separate features and target\n",
    "X_train = train_data[input_features]\n",
    "y_train = train_data[target_feature]\n",
    "X_validate = validate_data[input_features]\n",
    "y_validate = validate_data[target_feature]\n",
    "X_test = test_data[input_features]\n",
    "y_test = test_data[target_feature]\n",
    "\n",
    "# Step 2: Create and train the decision tree classifier\n",
    "decision_tree = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Compute the accuracy on the training and testing data\n",
    "train_accuracy = accuracy_score(y_train, decision_tree.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, decision_tree.predict(X_test))\n",
    "print(f\"Training Accuracy: {train_accuracy}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Step 4: Plot the tree and identify the most impure node\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(decision_tree, feature_names=input_features, class_names=np.unique(y_train), filled=True)\n",
    "plt.show()\n",
    "\n",
    "# Step 5: Identify the most impure node at level 1 and apply k-means\n",
    "# Note: You will need to write additional code here to identify the most impure node and extract its samples\n",
    "# This is an example placeholder for k-means clustering on the samples from the most impure node\n",
    "# Replace 'samples_from_impure_node' with the actual data from the impure node\n",
    "k = 3  # Choose an appropriate value for k based on your analysis\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "kmeans.fit(samples_from_impure_node)\n",
    "\n",
    "# Plotting the results of k-means\n",
    "plt.scatter(samples_from_impure_node[:, 0], samples_from_impure_node[:, 1], c=kmeans.labels_, cmap='viridis')\n",
    "plt.title('K-Means Clustering on the Most Impure Node')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
